---
title: Agent Tokens
description: "Understand how Same measures usage with agent tokens and how to optimize it."
---

## What are Agent Tokens?

Same uses "agent tokens" as the primary unit to measure the resources consumed during your interactions. Think of tokens as pieces of words or code that Same processes.

- **Roughly:** 1 token is about 4 characters in English.
- **Example:** 1,500 words is approximately 2,048 tokens.

Every interaction, from understanding your prompts and context to generating code and using tools, consumes agent tokens.

## How Usage is Calculated

Your token usage is calculated based on the complexity and size of each request you make to Same. The key factors are:

1.  **Input Tokens (Context):** This includes:

    - Your prompt text.
    - The content of any files, images, or chat summaries you provide as context using the `@ Add context` button.
    - The conversation history included in the request.
    - **Calculation:** **10%** of these input tokens are counted towards your usage for each request.

2.  **Output Tokens (Response):** This includes:
    - The code, text, or reasoning generated by Same.
    - Tokens used by tools (e.g., file edits, terminal commands, web searches) and their results.
    - **Calculation:** **100%** of these output tokens are counted towards your usage.

**Total Usage per Request = (10% of Input Tokens) + (100% of Output Tokens)**

<Frame caption="View total model context through the chat input box.">
  <img
    src="/images/model-context.png"
    alt="Screenshot showing the chat input box with 'Model context'."
  />
</Frame>

<Info>
  **Context Window Limits:** Same uses powerful models like Claude Sonnet 3.7,
  which have large context windows (up to 200,000 tokens). However, performance
  can degrade beyond ~120,000 tokens. Managing context size is key for optimal
  results and cost-efficiency.
</Info>

## Optimizing Token Usage

- **Start New Chats Frequently:** Treat each chat like a specific task or feature. This keeps the context window smaller and focused, leading to better performance and lower costs. A summary of previous work is automatically attached to new chats for continuity. See [Maximizing Performance](/performance/maximizing-performance).
- **Use `@ Add context`:** Instead of relying on long conversation history or Same's exploration, create new chats often and use the `@ Add context` button to provide specific files or chat summaries relevant to your current request. This is much more token-efficient.
- **Be Specific:** Clear, concise prompts require fewer tokens for Same to understand and generate relevant output.
- **Monitor Usage:** Keep an eye on your token consumption in your account settings.

## Monitoring Your Usage

You can monitor your token usage within Same. Your remaining token balance and usage history are available in your account settings.

<Frame caption="View your token usage in account settings">
  <img
    src="/images/view-usage.png"
    alt="Screenshot showing where to view token usage in account settings"
  />
</Frame>

<Info>
  Understanding token usage helps you optimize your interactions with Same and
  manage your plan effectively. For details on pricing, see our [Pricing
  page](/usage/pricing).
</Info>
